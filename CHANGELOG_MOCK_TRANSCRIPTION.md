# Changelog: Mock Transcription MVP

## Дата: 26 октября 2025

### Добавлена новая функциональность

#### 1. Генерация mock-разговоров через OpenAI API

**Backend:**
- ✅ Создан `app/openai_service.py` - сервис для работы с OpenAI API
  - `generate_conversation()` - генерация реалистичных диалогов врач-пациент с временными метками (MM:SS)
  - `extract_anamnesis_data()` - извлечение структурированных данных (цель обращения, жалобы, анамнез)

- ✅ Добавлены новые API endpoints в `app/api/audio.py`:
  - `POST /api/audio/generate-mock-conversation?appointment_id={id}` - генерация разговора
  - `POST /api/audio/{audio_id}/extract-anamnesis` - извлечение анамнеза из транскрипции
  - `POST /api/audio/extract-anamnesis-by-appointment?appointment_id={id}` - вспомогательный endpoint

- ✅ Обновлена конфигурация `app/config.py`:
  - Добавлены параметры: `openai_api_key`, `openai_base_url`, `openai_model`

**Frontend:**
- ✅ Обновлён `static/js/audio-handler.js`:
  - Добавлена кнопка "Сгенерировать разговор (AI)" на вкладке "Стенограмма"
  - Отображение сгенерированной транскрипции с временными метками
  - Кнопка "Извлечь анамнез из разговора"
  - Автоматический переход на вкладку "Анамнез" после извлечения

**Конфигурация:**
- ✅ Обновлён `requirements.txt` - добавлена библиотека `openai>=1.0.0`
- ✅ Создан `.env.example` - шаблон конфигурации
- ✅ Создан `OPENAI_SETUP.md` - подробная документация по настройке

### Архитектурные решения

1. **Интеграция с OpenAI:**
   - Использован официальный Python клиент OpenAI
   - Асинхронные вызовы API для неблокирующей работы
   - Структурированный вывод (JSON) для извлечения анамнеза

2. **Промпты:**
   - Генерация: создание медицинского диалога 5-7 минут с метками времени
   - Извлечение: структурирование данных в формате JSON с полями purpose, complaints, anamnesis

3. **Безопасность:**
   - API ключи хранятся в `.env` файле (не коммитятся в git)
   - Валидация входных данных
   - Обработка ошибок с логированием

4. **UX:**
   - Понятный UI с градиентными кнопками
   - Индикаторы прогресса при генерации
   - Toast-уведомления о статусе операций
   - Автоматический переход на вкладку анамнеза после извлечения

### Использование

#### Шаг 1: Настройка

```bash
# 1. Создайте .env файл
cp .env.example .env

# 2. Добавьте ваш OpenAI API ключ
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4

# 3. Установите зависимости
pip install -r requirements.txt

# 4. Запустите приложение
uvicorn app.main:app --reload
```

#### Шаг 2: Использование в интерфейсе

1. Откройте карточку пациента
2. Перейдите на вкладку **"Стенограмма"**
3. Нажмите **"Сгенерировать разговор (AI)"**
4. Дождитесь генерации диалога (~5-15 секунд)
5. Просмотрите транскрипцию с временными метками
6. Нажмите **"Извлечь анамнез из разговора"**
7. Перейдите на вкладку **"Анамнез"** для просмотра заполненных полей

### Технические детали

#### Формат транскрипции

```
00:00 - Врач: Здравствуйте! Проходите, присаживайтесь. Что вас беспокоит?
00:15 - Пациент: Добрый день, доктор. Последние несколько дней...
02:30 - Врач: Понятно. А когда именно начались эти симптомы?
...
```

#### Поля анамнеза

Автоматически заполняются:
- **Цель обращения** (purpose) - краткая суть обращения
- **Жалобы пациента** (complaints) - детальные жалобы
- **Анамнез** (anamnesis) - история заболевания, осмотр, диагноз, рекомендации

#### Модели БД

Используются существующие модели:
- `AudioFile.transcription_text` - хранение сгенерированного диалога
- `AudioFile.transcription_status` - статус (COMPLETED после генерации)
- `MedicalReport` - хранение извлечённых данных анамнеза

### Стоимость

Приблизительная стоимость за один полный цикл (генерация + извлечение):

**GPT-4:**
- ~$0.10-0.15 за цикл
- ~2500-3500 tokens

**GPT-3.5-Turbo:**
- ~$0.005-0.01 за цикл
- ~2500-3500 tokens

### Логирование

Все операции логируются:
```
INFO: Запрос генерации mock-разговора для приёма: appointment_id=1
INFO: Диалог успешно сгенерирован, длина: 2345 символов
INFO: Запрос извлечения анамнеза из транскрипции: audio_id=5
INFO: Данные анамнеза успешно извлечены
```

### Возможные улучшения

Для будущих версий:
- [ ] Кэширование сгенерированных разговоров
- [ ] Возможность редактирования транскрипции перед извлечением
- [ ] Поддержка различных специализаций врачей
- [ ] Настройка длительности разговора
- [ ] Экспорт транскрипции в различных форматах
- [ ] Аудио-генерация из текста (TTS)

### Известные ограничения

1. Требуется валидный OpenAI API ключ
2. Зависит от доступности OpenAI API
3. Время генерации зависит от загрузки API (~5-15 секунд)
4. Стоимость зависит от выбранной модели

### Файлы изменены

```
Создано:
+ app/openai_service.py
+ OPENAI_SETUP.md
+ CHANGELOG_MOCK_TRANSCRIPTION.md
+ .env.example (если не существовал)

Изменено:
~ requirements.txt
~ app/config.py
~ app/api/audio.py
~ static/js/audio-handler.js

Не изменялось:
- app/models.py (используются существующие модели)
- app/schemas.py (используются существующие схемы)
- app/crud.py (используются существующие функции)
```

### Тестирование

Для тестирования:

```bash
# 1. Убедитесь что .env настроен
cat .env | grep OPENAI

# 2. Запустите приложение
uvicorn app.main:app --reload

# 3. Откройте браузер
# http://localhost:8000

# 4. Выберите любого пациента
# 5. Перейдите на вкладку "Стенограмма"
# 6. Нажмите "Сгенерировать разговор (AI)"
# 7. Проверьте транскрипцию
# 8. Нажмите "Извлечь анамнез"
# 9. Проверьте вкладку "Анамнез"
```

### Поддержка

При проблемах:
1. Проверьте логи: `logs/elia-app-*.log`
2. Проверьте настройки в `.env`
3. См. подробную документацию в `OPENAI_SETUP.md`

